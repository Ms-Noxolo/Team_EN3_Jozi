{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Ms-Noxolo/Team_EN3_Jozi/blob/master/Predict_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m-nkZpMWBqnQ"
   },
   "source": [
    "# Team EN3 Unsupervised Learning predict\n",
    "\n",
    "### Kaggle Submission: Team_EN3_\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0pH6W5NDOX7"
   },
   "source": [
    "**Team Members:** Refiloe Phipa, Selebogo Mosoeu, Itumeleng Ngoetjana, Noxolo Kheswa, Jamie Japhta, Nkopane\n",
    "\n",
    "**Supervisor :** Ebrahim Noormahomed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "niygTTlPF6Gs"
   },
   "source": [
    "### Table of content\n",
    "---\n",
    "1.   [Introduction](#intro)\n",
    "  *   Background\n",
    "  *   Problem statement\n",
    "---\n",
    "2.   [Load Dependencies](#imports)\n",
    "---\n",
    "3.   [Data Overview](#Overview)\n",
    "  *   Shape\n",
    "  *   Information about data\n",
    "  *   features\n",
    "---\n",
    "4.   [Data preprocessing](#preprocessing)\n",
    "  *   Detecting and correcting corrupt data\n",
    "---\n",
    "5.   [Exploratory Data Analysis](#EDA)\n",
    "  *   The number of movies being released\n",
    "  *   The number of ratings for the movies released\n",
    "  *   The years with majority of movies being released\n",
    "  *   The kind of movies that are being released\n",
    "  *   The runtime of movies that are being released\n",
    "---\n",
    "6.   [Modelling](#modelling)\n",
    "  *   Content Based Filtering\n",
    "  *   Cosine Similarity\n",
    "  *   Collaborative Filtering\n",
    "  *   Movie Recommendations\n",
    "  *   Surprise\n",
    "  *   Single Rating Prediction\n",
    "  *   Multiple Ratings Prediction\n",
    "---\n",
    "7.   [Performance Evaluation](#evaluation)\n",
    "---\n",
    "8.   [Conclusion](#ending)\n",
    "---\n",
    "9.  [References](#ending)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTF2sD3qE8Bh"
   },
   "source": [
    "# 1. Introduction\n",
    "\n",
    "### Background\n",
    "\n",
    "In today’s technology driven world, recommender systems are socially and economically critical for ensuring that individuals can make appropriate choices surrounding the content they engage with on a daily basis. One application where this is especially true surrounds movie content recommendations; where intelligent algorithms can help viewers find great titles from tens of thousands of options.\n",
    "\n",
    "Recommender systems require a broad base access of the user's historical preferences as a result increasing the insights and the accuracy of its future predictions. We can implement an unsupervised machine learning algorithm to solve this problem.\n",
    "\n",
    "Machine learning is the study of computer algorithms that improve automatically through experience. It is a powerful branch of Artificial intelligence, dating as far back as 1952. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.\n",
    "\n",
    "Unsupervised learning is a type of machine learning that looks for previously undetected patterns in a data set with no pre-existing labels and with a minimum of human supervision.\n",
    "\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Build an unsupervised machine learning model that is capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences and/or based on content or collaborative filtering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IMlG2XaXmDOV"
   },
   "source": [
    "# 2. Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "DWt78EugTAR5",
    "outputId": "72058fdc-4f3a-4677-f306-dfe5f2b162dc"
   },
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import json\n",
    "%matplotlib inline\n",
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "!pip install scikit-surprise\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from surprise import NormalPredictor\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "U29kIQrDMPIQ",
    "outputId": "d66477b1-064d-4501-f22f-0b202a129635"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0H2OrHCK-cc"
   },
   "outputs": [],
   "source": [
    "# loading in the datasets\n",
    "movies = pd.read_csv(\"data/movies.csv\")\n",
    "links = pd.read_csv('data/links.csv')\n",
    "imdb = pd.read_csv('data/imdb_data.csv')\n",
    "tags = pd.read_csv('data/tags.csv')\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "#scores = pd.read_csv('genome_scores.csv')\n",
    "Sample_Submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tj85m-Vol_2A"
   },
   "source": [
    "# 3. Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r204txNzNMSe"
   },
   "source": [
    "Below we take a general review and summary of the datasets taking note of the shapes, info and features i.e. columns all of which will help us establish a good approach into performing the exploratory data analyses of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "p8q0PXETmetq",
    "outputId": "c5e17a51-9fd4-49f8-82c6-c7c391655e51"
   },
   "outputs": [],
   "source": [
    "# The movies\n",
    "print(movies.shape)\n",
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "-E6OTZzbMCRi",
    "outputId": "6fde468f-3da5-4e2e-8844-5a4c11c2366f"
   },
   "outputs": [],
   "source": [
    "# The links\n",
    "print(links.shape)\n",
    "links.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ppEM6w1NWnK"
   },
   "source": [
    "Given the similar shape of the movie and links i.e. movie homepage dataframes, we can already note that the links dataframe contains information relating to the movies file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "BLSdm6FbMCOR",
    "outputId": "a944bed3-066e-436a-dbad-94bbc22a80d1"
   },
   "outputs": [],
   "source": [
    "# The imdb\n",
    "print(imdb.shape)\n",
    "imdb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOggmtDHNyLo"
   },
   "source": [
    "This dataframe consists of additional movie metadata scraped from IMDB using the links.csv file. These include cast/crew, budgets, plots as well as the runtime. The IMDB platform has its own movie-listing requirements therefore this could be the reason why the dataframe doesn't capture all the movies in the links.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "WtmwOCZgNHOo",
    "outputId": "1da3a223-a1c0-4280-b068-0bde893e20e9"
   },
   "outputs": [],
   "source": [
    "# The tags \n",
    "print(tags.shape)\n",
    "tags.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnk1GYPVNHK-"
   },
   "outputs": [],
   "source": [
    "#print(scores.shape)\n",
    "#scores.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6hT01WeN82a"
   },
   "source": [
    "We see that the scores and tags dataframes contain information about the movies which can be used ior included in creating a meatadata dataframe of the movies which can be very useful in building a suitable recommender systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "dkRxK5JuMCY4",
    "outputId": "6251c014-19cf-44ba-9325-f7e332e99999"
   },
   "outputs": [],
   "source": [
    "# The training \n",
    "print(train.shape)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_GZqmyeNrVX"
   },
   "source": [
    "It is not surpring that this dataframe has alomst 2x more entries than the movie dataset because an individual user can watch more than one movies and also provide ratings for a selection of various movies. This dataframe can also be taken as a ratings table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "LQe6e_WIMCWR",
    "outputId": "0d05c1d1-501f-4809-b8a5-5696c872e6bd"
   },
   "outputs": [],
   "source": [
    "# Creating a new dataframe from a subset of the train data \n",
    "ratings = train.copy()\n",
    "ratings.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "_XqFOnbbu-F6",
    "outputId": "df7946e5-dcdc-480c-f614-e7f368183db8"
   },
   "outputs": [],
   "source": [
    "# Since we're considering the train as ratings, it is useful to check for missing values,\n",
    "ratings.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "TytGbEiYu-GG",
    "outputId": "82f6114f-ff30-4984-841d-7d176524b7dc"
   },
   "outputs": [],
   "source": [
    "# as well as the datatype:\n",
    "ratings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYEWr1csu-GP"
   },
   "source": [
    "There are no missing values in the dataframe and it consists of only numeric values. That's Good! However, we may need to use only a subset of the dataframe to build and train our models as it becomes impossible work with a huge dataset depending on one's computational power.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "dflrL62HNHH0",
    "outputId": "4344b2ca-46be-4641-8ef6-2b9b733c7937"
   },
   "outputs": [],
   "source": [
    "# Overview of the testing dataframe\n",
    "print(test.shape)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_rDIUZqOKct"
   },
   "source": [
    "This dataset that will be used in testing the algorithms build for constructing recommender systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MQlZ1XXmtJe"
   },
   "source": [
    "# 4. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZwlH-HF8OnBv"
   },
   "source": [
    "Data preprocessing is the process of detecting and correcting corrupt or inaccurate records from the dataset and identifying incomplete, incorrect, inaccurate or irrelevant parts of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jj-9IK4cPAM-",
    "outputId": "4ae28556-ffed-4c78-93c7-0b664fca7f44"
   },
   "outputs": [],
   "source": [
    "users = len(ratings.userId.unique())\n",
    "items = len(ratings.movieId.unique())\n",
    "print('There are {} unique users and {} unique movies in this data set'.format(users, items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "JdxL6650PAUV",
    "outputId": "c09fa281-c340-46ae-b6f8-e01c74cbaf33"
   },
   "outputs": [],
   "source": [
    "max_userId = ratings.userId.max()\n",
    "max_itemId = ratings.movieId.max()\n",
    "print('There are {} distinct users and the max of user ID is also {}'.format(users, max_userId))\n",
    "print('There are {} distinct movies, however, the max of movie ID is {}'.format(items, max_itemId))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8z2p128GQ4pO"
   },
   "source": [
    "For matrix factorization, a item vector that is in unnecessarily high dimensional space requires data cleaning to reduce the dimension of item vector back to the number of items i.e.Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dvcDK3PpPAaF"
   },
   "outputs": [],
   "source": [
    "def reduce_dim(df_ratings):\n",
    "    \"\"\"\n",
    "    Reduce item vector dimension to the number of distinct items in our data sets\n",
    "    \n",
    "    input: pd.DataFrame, df_ratings should have columns ['userId', 'movieId', 'rating']\n",
    "    output: pd.DataFrame, df_ratings with new 'MovieID' that is compressed\n",
    "    \"\"\"\n",
    "    # pivot\n",
    "    df_user_item = df_ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "    # reset movieId\n",
    "    df_user_item = df_user_item.T.reset_index(drop=True).T\n",
    "    # undo pivot/melt - compress data frame\n",
    "    df_ratings_new = df_user_item \\\n",
    "        .reset_index('userId') \\\n",
    "        .melt(\n",
    "            id_vars='userId', \n",
    "            value_vars=df_user_item.columns,\n",
    "            var_name='movieId',\n",
    "            value_name='rating')\n",
    "    # drop nan and final clean up\n",
    "    return df_ratings_new.dropna().sort_values(['userId', 'movieId']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "c_IsTMsrPAKm",
    "outputId": "4cf790a4-5075-4252-a4fd-d1cc53bb2e92"
   },
   "outputs": [],
   "source": [
    "print('reduce item dimension before:')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "HahTMPKYPAIV",
    "outputId": "4bd25efc-5777-4b49-c36c-6b8290e4fd55"
   },
   "outputs": [],
   "source": [
    "new_ratings = reduce_dim(ratings.copy()[:100])\n",
    "print('reduce item dimension after:')\n",
    "new_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_wqnFylnRgb3"
   },
   "source": [
    "An alternative Filtering and cleaning method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4GpphI8PAFG"
   },
   "outputs": [],
   "source": [
    "# Limiting the ratings to user ratings that have rated more that 25 movies:\n",
    "ratings_f = ratings.groupby('userId').filter(lambda x: len(x) >= 25)\n",
    "\n",
    "# Creating a list with movie titles that survived the filtering:\n",
    "movie_list_rating = ratings_f.movieId.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eUE26QXYRnf-",
    "outputId": "c845db5d-d8cf-476c-cf98-dde0a0ddf581"
   },
   "outputs": [],
   "source": [
    "# The prop of the original movie titles in ratings data frame that we have retained:\n",
    "len(ratings_f.movieId.unique())/len(movies.movieId.unique()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kpI5EM3QRnbq",
    "outputId": "f6275a25-1680-4799-cc5f-77779eb568d0"
   },
   "outputs": [],
   "source": [
    "# The prop of the users in ratings data frame that we have retained:\n",
    "len(ratings_f.userId.unique())/len(ratings.userId.unique()) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQOtAdLtu-H9"
   },
   "source": [
    "Choosing the users who rated more than 25 items and the items that have more than 25 ratings helps ensure that we remain within the confines of the memory limitation in our machine. \n",
    "However, we did keep the dataset as it while working on cloud i.e. Kaggle, AWS EC2 instance. So now that we have somemwhat finalized the size and type of dataset we will be building and training models with, we can continue with cleaning the data some more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCM5XuRwRt6e"
   },
   "outputs": [],
   "source": [
    "# Using the results to filter the movies data frame:\n",
    "movies = movies[movies.movieId.isin(movie_list_rating)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13NzdSglmrnE"
   },
   "outputs": [],
   "source": [
    "# Storing the years from the titles separately:\n",
    "\n",
    "# We specify the parantheses so we don’t conflict with movies that have years in their titles\n",
    "movies[\"year\"] = movies.title.str.extract(\"(\\(\\d\\d\\d\\d\\))\",expand=False)\n",
    "# Removing the parentheses\n",
    "movies[\"year\"] = movies.year.str.extract(\"(\\d\\d\\d\\d)\",expand=False)\n",
    "# Removing the years from the ‘title’ column\n",
    "movies[\"title\"] = movies.title.str.replace(\"(\\(\\d\\d\\d\\d\\))\", \"\")\n",
    "# Applying the strip function to get rid of any ending whitespace characters that may have appeared\n",
    "movies[\"title\"] = movies[\"title\"].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLzvZZYBu-Ie"
   },
   "outputs": [],
   "source": [
    "# Removing the character separating the genres for each movie\n",
    "movies['genres'] = movies['genres'].str.replace('|',' ')\n",
    "\n",
    "# Removing the same character for the meatadata:\n",
    "imdb['title_cast'] = imdb['title_cast'].str.replace('|',' ')\n",
    "imdb['plot_keywords'] = imdb['plot_keywords'].str.replace('|',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "ktkB3ImWu-Il",
    "outputId": "d7b26e21-3877-4707-aecd-2d6785a63705"
   },
   "outputs": [],
   "source": [
    "# Viewing the dataframes: Movies\n",
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TacIN56Rt1s"
   },
   "outputs": [],
   "source": [
    "# map movie to id:\n",
    "Mapping_file = dict(zip(movies.title.tolist(), movies.movieId.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "Ef8BX4idu-I2",
    "outputId": "b30fa970-1f96-4b37-e0e4-1a80a10d1788"
   },
   "outputs": [],
   "source": [
    "# Viewing the dataframes: imdb\n",
    "imdb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVYql_SiR0tQ"
   },
   "outputs": [],
   "source": [
    "# Dropping the timestamps as they are considered not useful since we have runtime data\n",
    "tags.drop(['timestamp'],1, inplace=True)\n",
    "ratings_f.drop(['timestamp'],1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OCt0rSh7R5Ut"
   },
   "source": [
    "Merging the movies and the tags dataframes to create a metadata tag for each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "VRQJLiHoR8nU",
    "outputId": "b903f4e0-2e48-47b2-ade0-81dab9b73f81"
   },
   "outputs": [],
   "source": [
    "# creating the mixed dataframe of movies title, genres and all user tags given to each movie\n",
    "mixed = pd.merge(movies, tags, on='movieId', how='left')\n",
    "mixed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gNaywGSxR9yJ",
    "outputId": "9db291d5-7801-4b73-a9df-7605de333278"
   },
   "outputs": [],
   "source": [
    "print(mixed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e9IkqFIxSPNc"
   },
   "source": [
    "Cleaning a new dataframe with the movie metadata tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "MsoQvRxnu-Jj",
    "outputId": "2333e80d-cf40-4918-e652-57c2b2bc758c"
   },
   "outputs": [],
   "source": [
    "# Creating metadata from tags and genres\n",
    "mixed.fillna(\"\", inplace=True)\n",
    "mixed = pd.DataFrame(mixed.groupby('movieId')['tag'].apply(\n",
    "                                          lambda x: \"%s\" % ' '.join(x)))\n",
    "Final = pd.merge(movies, mixed, on='movieId', how='left')\n",
    "Final ['metadata'] = Final[['tag', 'genres']].apply(\n",
    "                                          lambda x: ' '.join(x), axis = 1)\n",
    "Final[['movieId','title','metadata']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mwieCgOu-Jw"
   },
   "source": [
    "Now we have created a new dataframe that will come in handy later when we tackle content-nased filering. Fow now, we proceed with some insight extractions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilLaVegxmizk"
   },
   "source": [
    "# 5. Exploratory Data Analysis\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RvdaCbSbURgZ"
   },
   "source": [
    "We need to perform investigative and detective analysis on our data to see if we can unearth any useful insights. We have data being generated from websites so it’s important to utilize Exploratory Data Analysis to analyze all this text data, with the aid of Visuals to help organizations make data-driven decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DqibDXHjTMrC"
   },
   "source": [
    "### The number of movies being released\n",
    "Knowing the numbers around movies can help paint a picture of the relationship that exists between movies and 'users' as availability of movies can be play a huge role in the general growth of the movie-audience industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "colab_type": "code",
    "id": "zZPY6RUZmz3k",
    "outputId": "c0164eb3-f1ac-4514-b4d6-14b9c64f0c71"
   },
   "outputs": [],
   "source": [
    "metadata = pd.merge(movies, imdb, on='movieId', how='left')\n",
    "# The number of Movies released per year\n",
    "num = metadata.groupby('year').count()\n",
    "plt.figure(figsize=(35,25))\n",
    "plt.plot(num.index, num['budget'])\n",
    "plt.xlabel(\"years\", size=25)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel('No. of Movies', size=25)\n",
    "plt.title('Number of Movies Released By year', size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vm_I43dpT2mo"
   },
   "source": [
    "Although there has been some drops in the number of movies released throughout the years, it is clear to see that there generally has been a significant growth in movies being released with the growth being exponential around 1990s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a4Q2n6OZu-KA"
   },
   "source": [
    "\n",
    "### The number of ratings for the movies released\n",
    "The general distribution of the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "ZEgVueZQu-KC",
    "outputId": "6627f875-27d4-4a8c-8270-26140c6d55d2"
   },
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "train_df = train[:20000]\n",
    "Ratings = train_df['rating'].value_counts().sort_index()\n",
    "Ratings.plot(kind='bar')\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('movie rating')\n",
    "plt.title('Count of movies by ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sjNKPpsnu-KL"
   },
   "source": [
    "There are more movies with ratings of 4.0, followed by 3.0, then 5.0. The issue here is that a movie may have been watched by one user and they might have given it a rating of 5.0. To curb this issue, there might be a need to consider only a movie whereby there we only 100 or more users who have watched the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Aa8Qfyx9u-KN",
    "outputId": "4df2e0ec-4408-4e93-a5ec-fbb0c09483dc"
   },
   "outputs": [],
   "source": [
    "# Evaluating the number of ratings a movie has received:\n",
    "no_of_ratings = train_df.groupby('movieId').count()['rating']\n",
    "no_of_ratings = no_of_ratings[no_of_ratings >= 10]\n",
    "new_ratings = train_df[train_df['movieId'].isin(no_of_ratings.index)]\n",
    "len(new_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "Gxh801pJu-Kl",
    "outputId": "348200a5-e424-4266-90bd-8c3b0ac6b597"
   },
   "outputs": [],
   "source": [
    "# Visually evaluating the number of ratings a movie has received:\n",
    "num_ratings = new_ratings['rating'].value_counts().sort_index()\n",
    "plt.figure(figsize=(8,5))\n",
    "num_ratings.plot(kind='bar')\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('movie rating')\n",
    "plt.title('Count of movies with 25 or more viewers by ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5mpNZch8u-Ku"
   },
   "source": [
    "There are still more movies with ratings of 4.0, followed by 3.0, then 5.0, with 0.5 and 1.5 ratings being the lowest as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "uCKO0MYcu-Kx",
    "outputId": "559e1637-3bc1-4272-a3fd-6458a08fb1d6"
   },
   "outputs": [],
   "source": [
    "# The average rating of movies in the database\n",
    "avg_rating = ratings_f.groupby('movieId')['rating'].mean()\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(8,5))\n",
    "avg_rating.plot(kind='hist')\n",
    "plt.ylabel('frequency')\n",
    "plt.xlabel('movie rating')\n",
    "plt.title('Average ratings of movies with 100 or more viewers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mszIXvOJu-LC"
   },
   "source": [
    "Unsuprisingly, there is a high distribution of movies in the region of 3.0 to 4.0 ratings. We now move on to wordcloud to visually summarise some of the insights we have extracted from the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_deY9fZ2T7lD"
   },
   "source": [
    "### The years with majority of movies being released\n",
    "Now we want to find out which years are dominating the movie industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "colab_type": "code",
    "id": "XA4kfbWXTQgN",
    "outputId": "60478b43-e079-47b4-f516-6b635b978d81"
   },
   "outputs": [],
   "source": [
    "# Looking at the all the years of movies releases\n",
    "year_corpus = metadata['year'].value_counts()\n",
    "# Generating the wordcolud\n",
    "year_wordcloud = WordCloud(background_color='white', height=2000, width=4000).generate_from_frequencies(year_corpus)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(year_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Firaoz_pUHhm"
   },
   "source": [
    "We can see that the wordcloud is correspodning with the plot above that the movie industry grew exponentially in the 2000s, with 2015 to 2017 being the most frequent yeas of movie releases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CtFUdW6cURSS"
   },
   "source": [
    "### The kind of movies that are being released\n",
    "Now we want to find out which movies, in terms of genre are dominating the movie industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "colab_type": "code",
    "id": "iHGtKEmqTQnZ",
    "outputId": "eb42fd2b-1353-4670-c252-4323589d0b09"
   },
   "outputs": [],
   "source": [
    "# Looking at the titles and checking for any similarity\n",
    "metadata['genres'] = metadata['genres'].astype('str')\n",
    "genre_corpus = ' '.join(metadata['genres'])\n",
    "#Generating the stopwords\n",
    "stopword = ['no genres', 'no', 'genres', 'genre', 'listed']\n",
    "# Generating the wordcolud\n",
    "genre_wordcloud = WordCloud(stopwords=stopword, background_color='white', height=2000, width=4000).generate(genre_corpus)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(genre_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8hbbh3iUUcE2"
   },
   "source": [
    "We can see that majority of the movies in the dataset are Comedy, Drama and Sci-Fi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "colab_type": "code",
    "id": "yiYOVdKWUn9j",
    "outputId": "04009cb6-700d-41ff-e04b-53e0d13dda5f"
   },
   "outputs": [],
   "source": [
    "# Looking at the titles and checking for any similarity\n",
    "metadata['title'] = metadata['title'].astype('str')\n",
    "title_corpus = ' '.join(metadata['title'])\n",
    "# Generating the wordcolud\n",
    "title_wordcloud = WordCloud(stopwords=STOPWORDS, background_color='white', height=2000, width=4000).generate(title_corpus)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(title_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tAorl6JUja9"
   },
   "source": [
    "As the worldcloud suggests, there are a lot of movies that tell the stories of a boy and/or girl as well as Love, movies about wars, crime, Day and Night events. These correspond to the genres unpacked above.\n",
    "\n",
    "The dataset consists of 27248 movies for which we have data on overview, cast/crew and budget. This is close to only 44% of the entire dataset. Although this is less than 505 of the entire dataset, it is more than enough to perform very useful analysis and discover interesting insights about the world of movies as these play a role in profiling a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "colab_type": "code",
    "id": "8EuEL8GVTQka",
    "outputId": "a4aed699-a78a-4dfc-fa55-84e35af0ebba"
   },
   "outputs": [],
   "source": [
    "# Looking at the plots and checking for any similarity\n",
    "metadata['plot_keywords'] = metadata['plot_keywords'].fillna(\" \").astype('str')\n",
    "overview_corpus = ' '.join(metadata['plot_keywords'])\n",
    "# Generating the wordcolud\n",
    "sw = ['based on', 'character', 'tell', 'name', 'reference', 'based', 'reference to']\n",
    "plot_wordcloud = WordCloud(stopwords=sw, background_color='white', height=2000, width=4000).generate(overview_corpus)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(plot_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5Dr1KCNu-MP"
   },
   "source": [
    "It is key to note that the imdb dataset cosists of only 27278 entries which is only 50% of the entire movie dataframe, as such, the plot key words are not a true represenation of the whole movie database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zrNXcKy8UxjP"
   },
   "source": [
    "### The runtime of movies that are being released\n",
    "Movies have progressed in terms of runtime, From the 1 minute slient, black & white clips to epic 3 hour gci. So, in this section, let us try and gain some additional insights about the nature of movie lengths and their evolution over time.\n",
    "\n",
    "Now we want to find out the duration of these movies being released are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "PWRU5CZGUduv",
    "outputId": "3952d1bb-9cc5-4b88-d9a7-8bff34c88b94"
   },
   "outputs": [],
   "source": [
    "# converting the column to numeric\n",
    "metadata['runtime'] = pd.to_numeric(metadata['runtime'])\n",
    "\n",
    "# Viewing relative durations of the movies\n",
    "metadata['runtime'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IgEVuyb_VKbB"
   },
   "source": [
    "Off the all the movies, 13007 which is only a subset of the dataset i.e. 22%, we can see that the average length of a movie is about 1 hour and 40 minutes. The longest movie recorded in this dataset is 877 minutes (or 14 hours) long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "id": "GeELA0WOUd2j",
    "outputId": "ecea36a9-310d-41b8-931e-5ae43ec8ec74"
   },
   "outputs": [],
   "source": [
    "# The distribution of these mainstream movies .i.e movies less than 3 hours (or 200 minutes) long. \n",
    "plt.figure(figsize=(12,6))\n",
    "sns.distplot(metadata[(metadata['runtime'] < 200) & (metadata['runtime'] > 0)]['runtime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TlMfnhwQVZMn"
   },
   "source": [
    "Possible trends in what may be considered as the appropriate length of a movie across the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "c-9ps9G-Ud0x",
    "outputId": "dcdaba8a-0eff-4bee-ee5f-87b67dcc5da4"
   },
   "outputs": [],
   "source": [
    "# Looking at the shortest Movies\n",
    "metadata[metadata['runtime'] > 0][['runtime', 'title', 'year']].sort_values('runtime').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KBYa6GC9Vhwt"
   },
   "source": [
    "Majority of the short movies were filmed in the late 1890s and the beginning of the 20th century and they're absurdly only a minute long. The exceptn in the Top 10 are Fresh Guacamole released in 2012 and Curb Dance released in 2010 both being two minutes long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "ZzsELC3xUdyL",
    "outputId": "f88e0f22-af1f-4793-f4a5-7156096355c0"
   },
   "outputs": [],
   "source": [
    "# Looking at the longest Movies\n",
    "metadata[metadata['runtime'] > 0][['runtime', 'title', 'year']].sort_values('runtime', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xl345V6nVtzY"
   },
   "source": [
    "Notably, almost all the entries in the above list were released in the 2000s and are actually miniseries and sequels and as such, can't count as feature length films. There isn't much insight we can gther from this as there is no way of distinguishing feature length films from TV Mini Series from our dataset unless done manually, and this could take days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "juQO3R3eUN7x"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdZPykMxm9S8"
   },
   "source": [
    "# 6. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4pWEuUmu-Ub"
   },
   "source": [
    "Two of the most popular ways to approach recommender systems are _collaborative filtering_ and _content-based_ recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P8cvmt10u-U7"
   },
   "source": [
    "### Surprise\n",
    "Surprise is a Python scikit building and analyzing recommender systems that deal with explicit rating data. We will be using it to develop and train our recommender models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxE8pByAXxe4"
   },
   "source": [
    "## Content Based Filtering\n",
    "\n",
    "A Content based filter uses attributes to recommend similar content.\n",
    "\n",
    "In a content-based recommender system, keywords are used to describe the items and a user profile is built to indicate the type of item this user likes. In other words, these algorithms try to recommend items that are similar to those that a user liked in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename = \"data/image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PKnhXRqzmRJs"
   },
   "outputs": [],
   "source": [
    "#Reload the data so that we can start on clean copies\n",
    "movies = pd.read_csv('movies.csv')\n",
    "imdb = pd.read_csv('imdb_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ZU06HQ2LYiXR",
    "outputId": "75a9f6c8-deb3-4bda-85a6-b801ec92a3b0"
   },
   "outputs": [],
   "source": [
    "#In order to best recommend a movie, we need to look at the list of movies we have. \n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7p_KhNCZX-A"
   },
   "source": [
    "Other features that could help or influence what a user may like include the cast, director or keywords.\n",
    "- This data can all be found in the imdb dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "fH9NFm00Yieb",
    "outputId": "279c96fe-10e8-4e5e-f360-ec56a8635bac"
   },
   "outputs": [],
   "source": [
    "imdb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBl6l8H7aDX_"
   },
   "source": [
    "The Combined relevant datasets\n",
    "\n",
    "The movie database has movie titles and genres and the imdb database has the cast, directors and keywords.\n",
    "We make it easier to view all of this information by combining them into one dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "upMUaDoTYiao",
    "outputId": "8bee7e56-e670-430e-e7f8-b68e646e2ce1"
   },
   "outputs": [],
   "source": [
    "alls = pd.merge(movies, imdb)\n",
    "alls.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "oY3HvyDeYiQd",
    "outputId": "8c52e69c-683e-45de-d671-ef5c139faccd"
   },
   "outputs": [],
   "source": [
    "# Checking for null values\n",
    "alls.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "0DEArcXqcR8X",
    "outputId": "c9c91a1e-9192-4cec-8f95-29c17c4de64a"
   },
   "outputs": [],
   "source": [
    "# Replace the null values.\n",
    "alls['title_cast'] = alls['title_cast'].fillna('')\n",
    "alls['director'] = alls['director'].fillna('')\n",
    "alls['plot_keywords'] = alls['plot_keywords'].fillna('')\n",
    "alls.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQcOnowBc5rn"
   },
   "source": [
    "We obeserve that both _Runtime_ and _budget_ do not really influence a user's choice in movie preferences so we drop it these columns rather than impute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqh4Av9kcSDx"
   },
   "outputs": [],
   "source": [
    "# Dropping columns that are not useful\n",
    "alls = alls.drop(['runtime', 'budget'], axis = 1)\n",
    "alls = alls.drop('movieId', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "dCLPRycsc4lV",
    "outputId": "8c055ad1-888e-447f-c700-8010b46e0be5"
   },
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "alls.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFE08L3QSMsg"
   },
   "outputs": [],
   "source": [
    "#Remove unneseccary characters and split information in columns\n",
    "alls['genres'] = alls.genres.str.split('|')\n",
    "alls['title_cast'] = alls.title_cast.str.split('|')\n",
    "alls['plot_keywords'] = alls.plot_keywords.str.split('|')\n",
    "alls['title'] = alls['title'].str.extract('(.*)\\((\\d{4})\\)', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8CWj4iKwSRYC"
   },
   "outputs": [],
   "source": [
    "#Let create a copy of our 'alls' data before we clean it so that our recommendation filtering does not return out movies in lowercase\n",
    "mov = alls.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44yWT1-te8xs"
   },
   "source": [
    "The dataframe is now cleaned so we ensure our system does not confuse names or movies that may start with the same first words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lsci5dHEeLl1"
   },
   "outputs": [],
   "source": [
    "# Creating a function to clean the metadata\n",
    "def clean(x):\n",
    "    \"\"\" This function converts the data to lowercase and remove any spaces.\n",
    "        i.e 'James Bond' is converted to 'jamesbond' and 'James Carter' to 'jamescarter'.\n",
    "        This ensures that such characters don't come across as the same character.\n",
    "    \"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        \n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "-uEe9De-eLpX",
    "outputId": "27b33d6f-54cd-484a-9b45-ce3385fec0a0"
   },
   "outputs": [],
   "source": [
    "# Applying the cleaning function\n",
    "for items in alls:\n",
    "    alls[items] = alls[items].apply(clean)\n",
    "\n",
    "# Looking at the cleaned dataframe\n",
    "alls.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnzUQ1K4gtdc"
   },
   "source": [
    "Now that we have clean the relevant data, we create our metadata soup that will be used in vectorizing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZMxW6WAShC2C"
   },
   "outputs": [],
   "source": [
    "# Creating a metadata soup for vectorizing\n",
    "def soup(x):\n",
    "    \"\"\" This function generates normlized text values \n",
    "        thus making it easy to vectorize the text.\n",
    "        i.e Loving to Love\n",
    "    \"\"\" \n",
    "    return ' '.join(x['genres']) + ' ' + ' '.join(x['title_cast']) + ' ' + x['director'] + ' ' + ' '.join(x['plot_keywords'])\n",
    "\n",
    "# Applying the function\n",
    "alls['soup'] = alls.apply(soup, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G2LQra7rhC5u"
   },
   "outputs": [],
   "source": [
    "# We then _reset the index_ so as to generate a new dataframe setting the indices in order, \n",
    "# starting from 0, making it easier to work with the dataframe.\n",
    "alls = alls.reset_index()\n",
    "indices = pd.Series(alls.index, index=alls['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Lo2shYjhyDm"
   },
   "source": [
    "CountVectorizer counts the word frequencies, unlike the TFIDFVectorizer we have used before in which the value increases proportionally to count, but is inversely proportional to frequency of the word in the corpus; that is the inverse document frequency (IDF) part.\n",
    "\n",
    "CountVectorizer thus provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words. Also enabling the preprocessing of text data prior to generating the vector representation making it a highly flexible feature representation module for text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oXiQTFZahDAF"
   },
   "outputs": [],
   "source": [
    "# Creating the instance of cv\n",
    "#data = alls['soup'][:10000]\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(alls['soup'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R7qY9i7Iu-a6"
   },
   "source": [
    "Can 200 components explain majority of the variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "HRktPrlbu-a7",
    "outputId": "d8845313-05b7-479f-8e49-636e6f838297"
   },
   "outputs": [],
   "source": [
    "# Using the same number of dimensions as before\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=200)\n",
    "latent_matrix_2 = svd.fit_transform(count_matrix)\n",
    "# plot var expalined to see what latent dimensions to use\n",
    "explained = svd.explained_variance_ratio_.cumsum()\n",
    "plt.plot(explained, '.-', ms = 16, color='red')\n",
    "plt.xlabel('Singular value components', fontsize= 12)\n",
    "plt.ylabel('Cumulative percent of variance', fontsize=12)        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1YfHmOcTGEj"
   },
   "source": [
    "This graph represents the cumulative variance that could be explained by the first 200 dimensions, which could be intepreted as one of the ways of calculating the system of coordinates i.e. variance using the SVD. It is thus another option for that we could consider for dimensionality reduction.\n",
    "\n",
    "Dimensionality Reduction\n",
    "- uncovers hidden correlations/features in the raw data.\n",
    "- allows us to remove redundant and noisy features that are not useful.\n",
    "- The tools help interpret and visualize the data easier.\n",
    "- It also creates easier access to data storage and processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dIbvEbAzipTe"
   },
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "Cosine similarity is correlation, which is greater for objects with similar angles and thus of great use for data _considered to be in_ high-dimensional positive spaces. It is metric that is used to determine how similar the data is by measuring the similarity between two non-zero vectors of an inner product space by a measure of the cosine of the angle between them. It is different to the latent matrix above whereby the user and item vectors are often called latent vectors are low-dimensional embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwP5UxprhC9X"
   },
   "outputs": [],
   "source": [
    "# Creating the instance of csine similarity\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oI7uOanUS3nV"
   },
   "source": [
    "Creating the Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlL-zM4XjLXa"
   },
   "outputs": [],
   "source": [
    "# Creating a function to recommend movies with\n",
    "def reco(title, cosine_sim = cosine_sim):\n",
    "    \"\"\" This function considers all our relevant features along \n",
    "        with the cosine similarity then returns a list of recommended movies.\n",
    "    \n",
    "    \"\"\"\n",
    "    index = indices[title]\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[index]))\n",
    "    sims = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sims = sims[1:11]\n",
    "\n",
    "    movie_indices = [i[0] for i in sims]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return alls['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5Pom667kgAS"
   },
   "source": [
    "Finally we are now able to suggest a movie and find other similar movies for our user to watch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "KGekcaXJTGFG",
    "outputId": "cbc20b5c-f914-4cbb-d31a-b3069ccb8d1a"
   },
   "outputs": [],
   "source": [
    "#We then put out function to the test by recommending 10 movies that a user that enjoyed jumanji may like. \n",
    "rec = reco('jumanji', cosine_sim)\n",
    "\n",
    "#We use our copy to ensure that the titles recommended, output as the original names and not in lowercase.\n",
    "movies.loc[rec.index.tolist()]['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "36jOEMGgWKfY"
   },
   "source": [
    "## Collaborative Filtering\n",
    "\n",
    "A technique that can filter out items that a user might like on the basis of reactions by similar users, and thus is entirely based on the past behavior and not on the context. \n",
    "\n",
    "- _User-User Collaborative Filtering:_ Finding look alike users based on similarity and recommend movies which first user’s look-alike has chosen in past.\n",
    "- _Item-Item Collaborative Filtering:_ It is quite similar to previous algorithm, but instead of finding user’s look-alike, we try finding movie’s look-alike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename = \"data/img.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEeHMj3su-iI"
   },
   "source": [
    "### Movie Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hq6EGMdTGF-"
   },
   "source": [
    "##### Memory-Based Collaborative filtering\n",
    "The approach is to create the user-similarity matrix wich will consist of some distance metrics that measure the similarity between any two pairs of users. Likewise, the item-similarity matrix will measure the similarity between any two pairs of items. \n",
    "\n",
    "Due to the limited computing power in our local machines, we will build the recommender system using only a subset of the ratings.i.e a sample of 20,000 ratings (2%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FgsqM9xau-cL",
    "outputId": "c9678444-9212-4f75-9767-5dee9cd9a69b"
   },
   "outputs": [],
   "source": [
    "# Looking at the ratings dataframe cleaned earlier\n",
    "print(ratings.shape)\n",
    "small_data = ratings[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8faKfBD2TGGF"
   },
   "outputs": [],
   "source": [
    "# Creating a new dataframe of movieId and titles\n",
    "new_df = movies.loc[:,['movieId','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "ypmZ0qlNTGG4",
    "outputId": "e94b2c39-54ae-4107-dfee-037de1a0dfe5"
   },
   "outputs": [],
   "source": [
    "# Merging data with titles to can create a pivot_table\n",
    "X = pd.merge(small_data, new_df, on = 'movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "colab_type": "code",
    "id": "bn6wIEcYTGHA",
    "outputId": "7f88dc25-abcf-42ef-e745-fbe10893826a"
   },
   "outputs": [],
   "source": [
    "# Creating a Table to pivot table so as to compare the movies for the recommendation\n",
    "table = X.pivot_table(index=['userId'], columns = ['title'],values = 'rating').fillna(0)\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f2V_budQTGHG"
   },
   "outputs": [],
   "source": [
    "# Creating a similarity table to can compare \n",
    "# the distance between movies using pearson correlation\n",
    "similarity_df = table.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5FfD43BoTGHQ"
   },
   "source": [
    "Given that the user has seen a movie and rated it, we are going to recommend him another movie using the rating that he gave to the movie he has seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mYW12xDYTGHR"
   },
   "outputs": [],
   "source": [
    "def find_movies(movie1,movie2,movie3):\n",
    "    def find_similar(movie_name):\n",
    "        '''This function takes in a 3 movie and \n",
    "        suggest 10 movies you might like based \n",
    "        on the similarities they have with the \n",
    "        movies you given to it'''\n",
    "        score = similarity_df[movie_name]\n",
    "        score = score.sort_values(ascending = False)\n",
    "        return score\n",
    "    movies = [movie1,movie2,movie3]\n",
    "    similar_movies = pd.DataFrame()\n",
    "    for movie in movies:\n",
    "        similar_movies = similar_movies.append(find_similar(movie))\n",
    "    similar_movies.head(10)\n",
    "    return pd.DataFrame(similar_movies.sum().sort_values(ascending=False).head(13)).drop(0,axis=1)[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "colab_type": "code",
    "id": "jiikC0_bkSAg",
    "outputId": "6705048e-3878-4b2e-f011-6aecccd61612"
   },
   "outputs": [],
   "source": [
    "#finally make the predictions\n",
    "find_movies('10 Cloverfield Lane','10 Cloverfield Lane','In Bruges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mmF3GWMLu-cu"
   },
   "source": [
    "#### Movie ratings predictions\n",
    "\n",
    "\n",
    "Evaluating the rating behaviour of users helps in creating their concrete profiles. We can use Singular Value Decomposition (SVD) which is a common dimensionality reduction technique. Given how most users have a pattern in the movies they watch and in the ratings they give to these movies, The ratings-matrix as per SVD has little unique information. This means that a low-rank matrix would be able to provide a good enough approximation for the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XL-CaWdBu-cx"
   },
   "source": [
    "#### _Suprise_\n",
    "\n",
    "\n",
    "Basic algorithms used in recommender systems:\n",
    "\n",
    "- NormalPredictor: predicts a random rating based on the distribution of the training set, which is assumed to be normal.\n",
    "- BaselineOnly: predicts the baseline estimate for given user and item.\n",
    "- KNNBasic: a basic collaborative filtering algorithm.\n",
    "- KNNWithMeans: a basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "- KNNBaseline: is a basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "- SVD algorithm is equivalent to Probabilistic Matrix Factorization\n",
    "- SVDpp algorithm is an extension of SVD that takes into account implicit ratings.\n",
    "- NMF is a collaborative filtering algorithm based on Non-negative Matrix Factorization. It is very similar with SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Matrix factorization model:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKOcx1FDWeAC"
   },
   "outputs": [],
   "source": [
    "# Loading the modules and models\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD, SVDpp, NormalPredictor, KNNBasic, BaselineOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gw2Rcw45u-c5"
   },
   "outputs": [],
   "source": [
    "# Loading in data\n",
    "df = train[:10000]\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['userId','movieId','rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "oY6oc6S2u-fS",
    "outputId": "0664f26e-2934-4d0a-e97b-6cb4cbf64ff6"
   },
   "outputs": [],
   "source": [
    "# Creating data to benchmark on:\n",
    "# Benchmarking algorithms\n",
    "models = ['SVD', 'SVDpp', 'NormalPredictor', 'KNNBasic', 'BaselineOnly']\n",
    "# empty list to capture rmse\n",
    "performance = []\n",
    "\n",
    "# train SVD on 75% of known rates\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "\n",
    "for model in [SVD, SVDpp, NormalPredictor, KNNBasic, BaselineOnly]:\n",
    "    \n",
    "    # Create an instance of the model\n",
    "    algo = model()\n",
    "    # Fit the model to the training data\n",
    "    algo.fit(trainset)\n",
    "    # Generate predictions\n",
    "    predictions = algo.test(testset)\n",
    "    # Compare predictions against actuals\n",
    "    rating_pred = accuracy.rmse(predictions)\n",
    "    # Extract only the name of the model\n",
    "    performance.append(rating_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGGeBiK3u-f2"
   },
   "source": [
    "N.B we only used a subset of the data due to the local machine's storage and computing power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "UoqYIAbju-f3",
    "outputId": "d79bef41-1c7d-48f7-eee9-7087132e3aed"
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe to store the rmse results of the models\n",
    "results = pd.DataFrame(data=performance, columns=['rmse'], index=models)\n",
    "# Sorting the results from best performance to worst\n",
    "results.sort_values('rmse', inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VyuYO6D9WhqM"
   },
   "source": [
    "SVD\n",
    "\n",
    "The Singular Value Decomposition (SVD), is a matrix factorisation technique, which reduces the number of features of a dataset by reducing the space dimension from N-dimension to K-dimension (where K < N), it is of no suprise that it and the SVDpp performed best out of the other models. Since SVD and SVDpp had the least RMSE value, we will tune the hyper-parameters of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "1zB7rq4-u-gJ",
    "outputId": "79e2357d-e1a9-4e0d-8871-76401cc8f76a"
   },
   "outputs": [],
   "source": [
    "# Tuning algorithm parameters with GridSearchCV to find the best parameters for the algorithm.\n",
    "# Using a subset of the data so that it runs quicker:\n",
    "subset = train[:5000]\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(subset[['userId','movieId','rating']], reader)\n",
    "\n",
    "# using the default parameters of GridSearch\n",
    "from surprise.model_selection.search import GridSearchCV\n",
    "param_grid = {'n_factors': [25, 30, 35, 40, 100], 'n_epochs': [15, 20, 25], 'lr_all': [0.001, 0.003, 0.005, 0.008],               'reg_all': [0.08, 0.1, 0.15, 0.02]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "algo = gs.best_estimator['rmse']\n",
    "print(gs.best_score['rmse']) \n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "# Assigning the values\n",
    "best = gs.best_params \n",
    "factors = best['rmse']['n_factors']\n",
    "epochs = best['rmse']['n_epochs'] \n",
    "lr_value = best['rmse']['lr_all']\n",
    "reg_value = best['rmse']['reg_all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R2PfH1i3W7vC"
   },
   "source": [
    "Now we tune our model hyperparameters and train our dataset and arrive at a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "4Zh5uXd5u-gm",
    "outputId": "f0e43a7c-f377-466e-a52e-52348568d66f"
   },
   "outputs": [],
   "source": [
    "# train SVD on 75% of known rates\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "algorithm = SVD(factors, epochs, lr_value, reg_value)\n",
    "algorithm.fit(trainset)\n",
    "predictions = algorithm.test(testset)\n",
    "\n",
    "# check the accuracy using Root Mean Square Error\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQHG2_Biu-gv"
   },
   "source": [
    "We observe that our rmse has improved from 1.065454 to 1.0500. Using GridSearch on a larger dataet on cloud, we were able to tune the model again and arrived at a score of 0.8314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "W-4GX-Kou-gx",
    "outputId": "1173e536-191c-4523-819f-f6bc078479fc"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename = \"data/Capture.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cqTYdSCyXV9_"
   },
   "source": [
    "For our prediction, we give the model a different users info (userId, movieId and their rating). It will then predict an estimate of what our user may rate this movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7qQTqx2zLgz"
   },
   "source": [
    "#### Single rating prediction\n",
    "\n",
    "Breakdown of what is fed into the model:\n",
    "\n",
    "\n",
    "* U = userId\n",
    "* I = movieId\n",
    "* Ri = rating\n",
    "\n",
    "Output\n",
    "* Ro = expected rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1cU-RCt_WeGc",
    "outputId": "ce22189e-b0d1-4fa2-f912-fce73ea36250"
   },
   "outputs": [],
   "source": [
    "# Predicting what a user with an Id of 1 would rate a movie with Id 1 i.e Toy Story\n",
    "U = 1\n",
    "I = 1\n",
    "Ro = algorithm.predict(U, I)\n",
    "print(Ro.est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNlFoU73XGYH"
   },
   "source": [
    "#### Multiple ratings predictions\n",
    "We use the test.csv to produce movie ratings of different movies by different users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7w--2SXMu-h9"
   },
   "outputs": [],
   "source": [
    "# Generating movie ratings predictions\n",
    "x = []\n",
    "test = test[:1000]\n",
    "for row in test.itertuples():\n",
    "    user = row.userId\n",
    "    item = row.movieId\n",
    "    test_preds = algorithm.predict(user, item)\n",
    "    rating = round(test_preds.est,1)\n",
    "    x.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPzs2_QxTGNy"
   },
   "outputs": [],
   "source": [
    "# Saving the rating predictions to the submission file\n",
    "# Sample_Submission['rating'] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZBpKLTHTGN2"
   },
   "source": [
    "Saving this submission df as a csv and uploading to the eda recommender system competion returns a score that tells us how well our model performs on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VzdFkI_RTGN5"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LMdofqynGa1"
   },
   "source": [
    "# 7. Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A4P95JfOomMc"
   },
   "source": [
    "#### Summary of the pros and cons of using **content-based recommendation**:\n",
    "\n",
    "Pros\n",
    "- There were no need for data on other users, thus no cold-start or sparsity problems.\n",
    "- It includes recommendations for both new & unpopular items\n",
    "- It can recommend to users with unique tastes.\n",
    "- It can provide explanations for recommended items that caused an item to be recommended (i.e genre and plot)\n",
    "\n",
    "Cons\n",
    "- It was rather hard to find the appropriate features to use.\n",
    "- It didn't recommend items outside users’ content profile.\n",
    "- It was also unable to exploit quality judgments of other users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gaKbmbYMowe0"
   },
   "source": [
    "#### Summary of the Memory-based Collaborative Filtering\n",
    "\n",
    "Pros\n",
    "- It is easy to implement and produce reasonable prediction quality.\n",
    "- This approach doesn’t require features about the items or users to be known.\n",
    "- It can thus help recommenders to not overspecialize in a user’s profile and recommend items that are completely different from what they have seen before. \n",
    "\n",
    "Cons\n",
    "- It doesn’t address the cold-start problem, i.e. new user(s) and/or new movie enters the system.\n",
    "- It suffers with sparse data, i.e. it’s hard to find users that have rated the same items.\n",
    "- It alos suffers when new users or items that don’t have any ratings enter the system.\n",
    "- It tends to favour and recommend popular items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZYzgUdPu-i2"
   },
   "source": [
    "### Hybrid cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HvRqHMsTGOW"
   },
   "source": [
    "Alternatively we could run a content/collaborative and hybrid cosine Similarity.\n",
    "Hybrid recommender systems combine two or more recommendation methods to gain better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4VGLcgJLu-i4"
   },
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "* We  the latent vectors for a selected movie from both content and collaborative matrixes:\n",
    "a_1 = np.array(latent_matrix_1_df.loc['Toy Story']).reshape(1, -1)\n",
    "a_2 = np.array(latent_matrix_2_df.loc['Toy Story']).reshape(1, -1)\n",
    "\n",
    "* Then calculate the similartity of this movie with the others in the list:\n",
    "score_1 = cosine_similarity(latent_matrix_1_df, a_1).reshape(-1)\n",
    "score_2 = cosine_similarity(latent_matrix_2_df, a_2).reshape(-1)\n",
    "\n",
    "* To find an average measure of both content and collaborative: \n",
    "hybrid = ((score_1 + score_2)/2.0)\n",
    "\n",
    "* Finally formulate a data frame of similar movies:\n",
    "dictDf = {'content': score_1 , 'collaborative': score_2, 'hybrid': hybrid} \n",
    "similar = pd.DataFrame(dictDf, index = latent_matrix_1_df.index )\n",
    "\n",
    "* Sort the dataframe on the basis of either: content, collaborative or hybrid,  i.e content\n",
    "similar.sort_values('content', ascending=False, inplace=True)\n",
    "\n",
    "similar[1:].head(11)\n",
    "\n",
    "\n",
    "Most commonly, collaborative filtering is combined with some other technique in an attempt to avoid the ramp-up problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MxZE3w3JnRAY"
   },
   "source": [
    "# 8. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "roURf_ieTmeG"
   },
   "source": [
    "A recommendaton system is a subclass of information filtering system that seeks to predict the rating or preference a user would give an item.\n",
    "- In this notebook, we built 2 recommendation models consisting of the content based filtering and collabractive filtering.\n",
    "- The content based filter took genres, cast, director and keywords as inputs to come up with the top 10 movies that would best fit a user.\n",
    "- The collabrative filter works by searching for a group of people with similar taste to this specific users using matrices. Which predict a rating for a user item pair based on the history of ratings given by the user and given to the item. The rating then help come up with recommendations. this filtering was built using the single value decomposition from the suprise library.\n",
    "- Applying The Hybrid Cosine Filter which combines our two recommendation models could be applied in the future to better improve the performance of the recommendation system.\n",
    "- However, we believe that with the 0.830 rmse score from using matrix factorization, we will be able to produce good recommendations to our users when deplying the engines on our streamlit-based app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tg212rryIvAO"
   },
   "source": [
    "# 9. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ozHsutcsk7Nf"
   },
   "source": [
    "1. Beginner Tutorial: Recommender Systems in Python\n",
    "https://www.datacamp.com/community/tutorials/recommender-systems-python\n",
    "\n",
    "2. Building Recommender Systems with Machine Learning and AI\n",
    "https://explore.udemy.com/course/building-recommender-systems-with-machine-learning-and-ai/learn/lecture/18187952#overview\n",
    "\n",
    "3. Build a Recommendation Engine With Collaborative Filtering\n",
    "https://realpython.com/build-recommendation-engine-collaborative-filtering/\n",
    "\n",
    "4. How to Build Simple Recommender Systems in Python\n",
    "https://medium.com/swlh/how-to-build-simple-recommender-systems-in-python-647e5bcd78bd\n",
    "\n",
    "5. Introduction to Recommendation System. Part 1\n",
    "https://hackernoon.com/introduction-to-recommender-system-part-1-collaborative-filtering-singular-value-decomposition-44c9659c5e75\n",
    "\n",
    "6. Building a Recommender System With Pandas\n",
    "https://medium.com/towards-artificial-intelligence/building-a-recommender-system-with-pandas-1ca0bb03fdce\n",
    "\n",
    "7. Building and Testing Recommender Systems With Surprise, Step-By-Step\n",
    "https://towardsdatascience.com/building-and-testing-recommender-systems-with-surprise-step-by-step-d4ba702ef80b\n",
    "\n",
    "8. Prototyping a Recommender System Step by Step Part 1: KNN Item-Based Collaborative Filtering\n",
    "https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-1-knn-item-based-collaborative-filtering-637969614ea\n",
    "\n",
    "9. Suprise\n",
    "http://surpriselib.com/\n",
    "\n",
    "10. Simple Movie Recommender Using SVD\n",
    "https://alyssaq.github.io/2015/20150426-simple-movie-recommender-using-svd/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Team_EN3_JHB_Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
