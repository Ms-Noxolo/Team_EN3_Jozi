{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Ms-Noxolo/Team_EN3_Jozi/blob/master/Team_EN3_JHB_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m-nkZpMWBqnQ"
   },
   "source": [
    "# Team EN3 Unsupervised Learning predict\n",
    "\n",
    "### Kaggle Submission: Team_EN3_\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0pH6W5NDOX7"
   },
   "source": [
    "**Team Members:** Refiloe Phipa, Selebogo Mosoeu, Itumeleng Ngoetjana, Noxolo Kheswa, Jamie Japhta, Nkopane\n",
    "\n",
    "**Supervisor :** Ebrahim Noormahomed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "niygTTlPF6Gs"
   },
   "source": [
    "### Table of content\n",
    "---\n",
    "1.   [Introduction](#intro)\n",
    "  *   Background\n",
    "  *   Problem statement\n",
    "---\n",
    "2.   [Load Dependencies](#imports)\n",
    "---\n",
    "3.   [Data cleaning](#cleaning)\n",
    "---\n",
    "4.   [Data preprocessing](#preprocessing)\n",
    "---\n",
    "5.   [Exploratory Data Analysis](#EDA)\n",
    "---\n",
    "6.   [Modelling](#modelling)\n",
    "---\n",
    "7.   [Performance Evaluation](#evaluation)\n",
    "---\n",
    "8.   [Conclusion](#ending)\n",
    "---\n",
    "9.  [References](#ending)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTF2sD3qE8Bh"
   },
   "source": [
    "# 1. Introduction\n",
    "\n",
    "### Background\n",
    "\n",
    "In today’s technology driven world, recommender systems are socially and economically critical for ensuring that individuals can make appropriate choices surrounding the content they engage with on a daily basis. One application where this is especially true surrounds movie content recommendations; where intelligent algorithms can help viewers find great titles from tens of thousands of options.\n",
    "\n",
    "Recommender systems require a broad base access of the user's historical preferences as a result increasing the insights and the accuracy of its future predictions. We can implement an unsupervised machine learning algorithm to solve this problem.\n",
    "\n",
    "Machine learning is the study of computer algorithms that improve automatically through experience. It is a powerful branch of Artificial intelligence, dating as far back as 1952. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.\n",
    "\n",
    "Unsupervised learning is a type of machine learning that looks for previously undetected patterns in a data set with no pre-existing labels and with a minimum of human supervision.\n",
    "\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Build an unsupervised machine learning model that is capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences based on content or collaborative filtering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IMlG2XaXmDOV"
   },
   "source": [
    "# 2. Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "DWt78EugTAR5",
    "outputId": "9f0cfaec-e6ad-4dc1-c62d-57666b1d5a28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (0.16.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.4.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import json\n",
    "%matplotlib inline\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "!pip install scikit-surprise\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from surprise import NormalPredictor\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U29kIQrDMPIQ"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0H2OrHCK-cc"
   },
   "outputs": [],
   "source": [
    "# loading in the datasets\n",
    "movies = pd.read_csv(\"movies.csv\")\n",
    "links = pd.read_csv('links.csv')\n",
    "imdb = pd.read_csv('imdb_data.csv')\n",
    "tags = pd.read_csv('tags.csv')\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "scores = pd.read_csv('genome_scores.csv')\n",
    "#Sample_Submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tj85m-Vol_2A"
   },
   "source": [
    "# 3. Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r204txNzNMSe"
   },
   "source": [
    "Below we take a general review and summary of the datasets taking note of the shapes, info and features i.e. columns all of which will help us establish a good approach into performing the exploratory data analyses of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8q0PXETmetq"
   },
   "outputs": [],
   "source": [
    "# The movies\n",
    "print(movies.shape)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-E6OTZzbMCRi"
   },
   "outputs": [],
   "source": [
    "# The links\n",
    "print(links.shape)\n",
    "links.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ppEM6w1NWnK"
   },
   "source": [
    "Given the similar shape of the movie and links i.e. movie homepage dataframes, we can already note that the links dataframe contains information relating to the movies file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLSdm6FbMCOR"
   },
   "outputs": [],
   "source": [
    "# The imdb\n",
    "print(imdb.shape)\n",
    "imdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOggmtDHNyLo"
   },
   "source": [
    "This dataframe consists of additional movie metadata scraped from IMDB using the links.csv file. These include cast/crew, budgets, plots as well as the runtime. The IMDB platform has its own movie-listing requirements therefore this could be the reason why the dataframe doesn't capture all the movies in the links.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtmwOCZgNHOo"
   },
   "outputs": [],
   "source": [
    "# The tags \n",
    "print(tags.shape)\n",
    "tags.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnk1GYPVNHK-"
   },
   "outputs": [],
   "source": [
    "print(scores.shape)\n",
    "scores.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6hT01WeN82a"
   },
   "source": [
    "We see that the scores and tags dataframes contain information about the movies which can be used ior included in creating a meatadata dataframe of the movies which can be very useful in building a suitable recommender systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dkRxK5JuMCY4"
   },
   "outputs": [],
   "source": [
    "# The training \n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_GZqmyeNrVX"
   },
   "source": [
    "It is not surpring that this dataframe has alomst 2x more entries than the movie dataset because an individual user can watch more than one movies and also provide ratings for a selection of various movies. This dataframe can also be taken as a ratings table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQe6e_WIMCWR"
   },
   "outputs": [],
   "source": [
    "# Creating a new dataframe from a subset of the train data \n",
    "ratings = train.copy()\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're considering the train as ratings, it is useful to check for missing values,\n",
    "ratings.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as well as the datatype:\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in the dataframe and it consists of only numeric values. That's Good! However, we may need to use only a subset of the dataframe to build and train our models as it becomes impossible work with a huge dataset depending on one's computational power.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dflrL62HNHH0"
   },
   "outputs": [],
   "source": [
    "# Overview of the testing dataframe\n",
    "print(test.shape\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_rDIUZqOKct"
   },
   "source": [
    "This dataset that will be used in testing the algorithms build for constructing recommender systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MQlZ1XXmtJe"
   },
   "source": [
    "# 4. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZwlH-HF8OnBv"
   },
   "source": [
    "Data preprocessing is the process of detecting and correcting corrupt or inaccurate records from the dataset and identifying incomplete, incorrect, inaccurate or irrelevant parts of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jj-9IK4cPAM-"
   },
   "outputs": [],
   "source": [
    "users = len(ratings.userId.unique())\n",
    "items = len(ratings.movieId.unique())\n",
    "print('There are {} unique users and {} unique movies in this data set'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JdxL6650PAUV"
   },
   "outputs": [],
   "source": [
    "max_userId = ratings.userId.max()\n",
    "max_itemId = ratings.movieId.max()\n",
    "print('There are {} distinct users and the max of user ID is also {}'.format(num_users, user_maxId))\n",
    "print('There are {} distinct movies, however, the max of movie ID is {}'.format(num_items, item_maxId))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8z2p128GQ4pO"
   },
   "source": [
    "For matrix factorization, a item vector that is in unnecessarily high dimensional space requires data cleaning to reduce the dimension of item vector back to the number of items i.e.Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dvcDK3PpPAaF"
   },
   "outputs": [],
   "source": [
    "def reduce_item_dim(df_ratings):\n",
    "    \"\"\"\n",
    "    Reduce item vector dimension to the number of distinct items in our data sets\n",
    "    \n",
    "    input: pd.DataFrame, df_ratings should have columns ['userId', 'movieId', 'rating']\n",
    "    output: pd.DataFrame, df_ratings with new 'MovieID' that is compressed\n",
    "    \"\"\"\n",
    "    # pivot\n",
    "    df_user_item = df_ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "    # reset movieId\n",
    "    df_user_item = df_user_item.T.reset_index(drop=True).T\n",
    "    # undo pivot/melt - compress data frame\n",
    "    df_ratings_new = df_user_item \\\n",
    "        .reset_index('userId') \\\n",
    "        .melt(\n",
    "            id_vars='userId', \n",
    "            value_vars=df_user_item.columns,\n",
    "            var_name='movieId',\n",
    "            value_name='rating')\n",
    "    # drop nan and final clean up\n",
    "    return df_ratings_new.dropna().sort_values(['userId', 'movieId']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_IsTMsrPAKm"
   },
   "outputs": [],
   "source": [
    "print('reduce item dimension before:')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HahTMPKYPAIV"
   },
   "outputs": [],
   "source": [
    "new_ratings = reduce_item_dim(ratings.copy())\n",
    "print('reduce item dimension after:')\n",
    "new_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_wqnFylnRgb3"
   },
   "source": [
    "An alternative Filtering and cleaning method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4GpphI8PAFG"
   },
   "outputs": [],
   "source": [
    "# Limiting the ratings to user ratings that have rated more that 25 movies:\n",
    "ratings_f = ratings.groupby('userId').filter(lambda x: len(x) >= 25)\n",
    "\n",
    "# Creating a list with movie titles that survived the filtering:\n",
    "movie_list_rating = ratings_f.movieId.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUE26QXYRnf-"
   },
   "outputs": [],
   "source": [
    "# The prop of the original movie titles in ratings data frame that we have retained:\n",
    "len(ratings_f.movieId.unique())/len(movies.movieId.unique()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kpI5EM3QRnbq"
   },
   "outputs": [],
   "source": [
    "# The prop of the users in ratings data frame that we have retained:\n",
    "len(ratings_f.userId.unique())/len(ratings.userId.unique()) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have somemwhat finalized the size and type of dataset we will be building and training models with, we can continue with cleaning the data some more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCM5XuRwRt6e"
   },
   "outputs": [],
   "source": [
    "# Using the results to filter the movies data frame:\n",
    "movies = movies[movies.movieId.isin(movie_list_rating)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13NzdSglmrnE"
   },
   "outputs": [],
   "source": [
    "# Storing the years from the titles separately:\n",
    "\n",
    "# We specify the parantheses so we don’t conflict with movies that have years in their titles\n",
    "movies[\"year\"] = movies.title.str.extract(\"(\\(\\d\\d\\d\\d\\))\",expand=False)\n",
    "# Removing the parentheses\n",
    "movies[\"year\"] = movies.year.str.extract(\"(\\d\\d\\d\\d)\",expand=False)\n",
    "# Removing the years from the ‘title’ column\n",
    "movies[\"title\"] = movies.title.str.replace(\"(\\(\\d\\d\\d\\d\\))\", \"\")\n",
    "# Applying the strip function to get rid of any ending whitespace characters that may have appeared\n",
    "movies[\"title\"] = movies[\"title\"].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the character separating the genres for each movie\n",
    "movies['genres'] = movies['genres'].str.replace('|',' ')\n",
    "\n",
    "# Removing the same character for the meatadata:\n",
    "imdb['title_cast'] = imdb['title_cast'].str.replace('|',' ')\n",
    "imdb['plot_keywords'] = imdb['plot_keywords'].str.replace('|',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TacIN56Rt1s"
   },
   "outputs": [],
   "source": [
    "# map movie to id:\n",
    "Mapping_file = dict(zip(movies.title.tolist(), movies.movieId.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVYql_SiR0tQ"
   },
   "outputs": [],
   "source": [
    "# Dropping the timestamps as they are considered not useful since we have runtime data\n",
    "tags.drop(['timestamp'],1, inplace=True)\n",
    "ratings_f.drop(['timestamp'],1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OCt0rSh7R5Ut"
   },
   "source": [
    "Merging the movies and the tags dataframes and creating a metadata tag for each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VRQJLiHoR8nU"
   },
   "outputs": [],
   "source": [
    "# creating the mixed dataframe of movies title, genres and all user tags given to each movie\n",
    "mixed = pd.merge(movies, tags, on='movieId', how='left')\n",
    "mixed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNaywGSxR9yJ"
   },
   "outputs": [],
   "source": [
    "print(mixed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e9IkqFIxSPNc"
   },
   "source": [
    "Cleaning this newly created metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create metadata from tags and genres\n",
    "mixed.fillna(\"\", inplace=True)\n",
    "mixed = pd.DataFrame(mixed.groupby('movieId')['tag'].apply(\n",
    "                                          lambda x: \"%s\" % ' '.join(x)))\n",
    "Final = pd.merge(movies, mixed, on='movieId', how='left')\n",
    "Final ['metadata'] = Final[['tag', 'genres']].apply(\n",
    "                                          lambda x: ' '.join(x), axis = 1)\n",
    "Final[['movieId','title','metadata']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilLaVegxmizk"
   },
   "source": [
    "# 5. Exploratory Data Analysis\n",
    "\n",
    "We need to perform investigative and detective analysis on our data to see if we can unearth any useful insights. We have data being generated from websites so it’s important to utilize Exploratory Data Analysis to analyze all this text data, with the aid of Visuals to help organizations make data-driven decisions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DqibDXHjTMrC"
   },
   "source": [
    "### The number of movies being released\n",
    "Knowing the numbers around movies can help paint a picture of the relationship that exists between movies and 'users' as availability of movies can be play a huge role in the general growth of the movie-audience industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZPY6RUZmz3k"
   },
   "outputs": [],
   "source": [
    "metadata = pd.merge(movies, imdb, on='movieId', how='left')\n",
    "# The number of Movies released per year\n",
    "num = metadata.groupby('year').count()\n",
    "plt.figure(figsize=(35,25))\n",
    "plt.plot(num.index, num['budget'])\n",
    "plt.xlabel(\"years\", size=25)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel('No. of Movies', size=25)\n",
    "plt.title('Number of Movies Released By year', size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vm_I43dpT2mo"
   },
   "source": [
    "Although there has been some drops in the number of movies released throughout the years, it is clear to see that there generally has been a significant growth in movies being released with the growth being exponential around 1990s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of ratings for the movies released\n",
    "The general distribution of the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "ratings.plot(kind='bar')\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('movie rating')\n",
    "plt.title('Count of movies by ratings');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more movies with ratings of 4.0, followed by 3.0, then 5.0. The issue here is that a movie may have been watched by one user and they might have given it a rating of 5.0. To curb this issue, there might be a need to consider only a movie whereby there we only 100 or more users who have watched the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the number of ratings a movie has received:\n",
    "no_of_ratings = ratings.groupby('movieId').count()['rating']\n",
    "no_of_ratings = no_of_ratings[no_of_ratings >= 10]\n",
    "no_of_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of these ratings cn be considered to be new?:\n",
    "new_ratings = ratings[ratings['movieId'].isin(no_of_ratings.index)]\n",
    "len(new_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do these numbers look visually?:\n",
    "plt.figure(figsize=(8,5))\n",
    "ratings.plot(kind='bar')\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('movie rating')\n",
    "plt.title('Count of movies with 10 or more viewers by ratings');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still more movies with ratings of 4.0, followed by 3.0, then 5.0, with 0.5 and 1.5 ratings being the lowest as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The average rating of movies in the database\n",
    "avg_rating = new_ratings.groupby('movieId')['rating'].mean()\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(8,5))\n",
    "avg_rating.plot(kind='hist')\n",
    "plt.ylabel('frequency')\n",
    "plt.xlabel('movie rating')\n",
    "plt.title('Average ratings of movies with 100 or more viewers');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsuprisingly, there is a high distribution of movies in the region of 3.0 to 4.0 ratings. We now move on to wordcloud to visually summarise some of the insights we have extracted from the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_deY9fZ2T7lD"
   },
   "source": [
    "### The years with majority of movies being released\n",
    "Now we want to find out which years are dominating the movie industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA4kfbWXTQgN"
   },
   "outputs": [],
   "source": [
    "# Looking at the all the years of movies releases\n",
    "year_corpus = metadata['year'].value_counts()\n",
    "# Generating the wordcolud\n",
    "year_wordcloud = WordCloud(background_color='white', height=2000, width=4000).generate_from_frequencies(year_corpus)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(year_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Firaoz_pUHhm"
   },
   "source": [
    "We can see that the wordcloud is correspodning with the plot above that the movie industry grew exponentially in the 2000s, with 2015 and 2016 being the most frequent yeas of movie releases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CtFUdW6cURSS"
   },
   "source": [
    "### The kind of movies that are being released\n",
    "Now we want to find out which movies, in terms of genre are dominating the movie industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHGtKEmqTQnZ"
   },
   "outputs": [],
   "source": [
    "# Looking at the titles and checking for any similarity\n",
    "metadata['genres'] = metadata['genres'].astype('str')\n",
    "genre_corpus = ' '.join(metadata['genres'])\n",
    "#Generating the stopwords\n",
    "stopword = ['no genres', 'no', 'genres', 'genre', 'listed']\n",
    "# Generating the wordcolud\n",
    "genre_wordcloud = WordCloud(stopwords=stopword, background_color='white', height=2000, width=4000).generate(genre_corpus)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(genre_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8hbbh3iUUcE2"
   },
   "source": [
    "We can see that majority of the movies in the dataset are Comedy, Drama and Romance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiYOVdKWUn9j"
   },
   "outputs": [],
   "source": [
    "# Looking at the titles and checking for any similarity\n",
    "metadata['title'] = metadata['title'].astype('str')\n",
    "title_corpus = ' '.join(metadata['title'])\n",
    "# Generating the wordcolud\n",
    "title_wordcloud = WordCloud(stopwords=STOPWORDS, background_color='white', height=2000, width=4000).generate(title_corpus)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(title_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tAorl6JUja9"
   },
   "source": [
    "As the worldcloud suggests, there are a lot of movies that pertain tell the stories of a boy and/or girl, movies about wars, crime, America and sequels as indicated by \"II\". These correspond to the genres unpacked above.\n",
    "\n",
    "The dataset consists of 27248 movies for which we have data on overview, cast/crew and budget. This is close to only 44% of the entire dataset. Although this is less than 505 of the entire dataset, it is more than enough to perform very useful analysis and discover interesting insights about the world of movies as these play a role in profiling a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8EuEL8GVTQka"
   },
   "outputs": [],
   "source": [
    "# Looking at the plots and checking for any similarity\n",
    "metadata['plot_keywords'] = metadata['plot_keywords'].astype('str')\n",
    "overview_corpus = ' '.join(metadata['plot_keywords'])\n",
    "# Generating the wordcolud\n",
    "plot_wordcloud = WordCloud(stopwords=STOPWORDS, background_color='white', height=2000, width=4000).generate(overview_corpus)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(plot_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zrNXcKy8UxjP"
   },
   "source": [
    "### The runtime of movies that are being released\n",
    "Movies have progressed in terms of runtime, From the 1 minute slient, black & white clips to epic 3 hour gci. So, in this section, let us try and gain some additional insights about the nature of movie lengths and their evolution over time.\n",
    "\n",
    "Now we want to find out the duration of these movies being released are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PWRU5CZGUduv"
   },
   "outputs": [],
   "source": [
    "# converting the column to numeric\n",
    "metadata['runtime'] = pd.to_numeric(metadata['runtime'])\n",
    "\n",
    "# Viewing relative durations of the movies\n",
    "metadata['runtime'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IgEVuyb_VKbB"
   },
   "source": [
    "\n",
    "This is only a subset of the dataset i.e. 22%, and from this wee can see that the average length of a movie is about 1 hour and 40 minutes. The longest movie recorded in this dataset is 877 minutes (or 14 hours) long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GeELA0WOUd2j"
   },
   "outputs": [],
   "source": [
    "# The distribution of these mainstream movies .i.e movies less than 3 hours (or 200 minutes) long. \n",
    "plt.figure(figsize=(12,6))\n",
    "sns.distplot(metadata[(metadata['runtime'] < 200) & (metadata['runtime'] > 0)]['runtime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TlMfnhwQVZMn"
   },
   "source": [
    "Possible trends in what may be considered as the appropriate length of a movie across the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-9ps9G-Ud0x"
   },
   "outputs": [],
   "source": [
    "# Looking at the shortest Movies\n",
    "metadata[metadata['runtime'] > 0][['runtime', 'title', 'year']].sort_values('runtime').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KBYa6GC9Vhwt"
   },
   "source": [
    "Majority of the short movies were filmed in the late 1890s and the beginning of the 20th century and they're absurdly only a minute long. The exceptn in the Top 10 are Fresh Guacamole released in 2012 and Curb Dance released in 2010 both being two minutes long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzsELC3xUdyL"
   },
   "outputs": [],
   "source": [
    "# Looking at the longest Movies\n",
    "metadata[metadata['runtime'] > 0][['runtime', 'title', 'year']].sort_values('runtime', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xl345V6nVtzY"
   },
   "source": [
    "Notably, almost all the entries in the above list were released in the 2000s and are actually miniseries and sequels and as such, can't count as feature length films. There isn't much insight we can gther from this as there is no way of distinguishing feature length films from TV Mini Series from our dataset unless done manually, and this could take days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGestSMTVltI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdZPykMxm9S8"
   },
   "source": [
    "# 6. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of the most popular ways to approach recommender systems are _collaborative filtering_ and _content-based_ recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suprise\n",
    "Surprise is a Python scikit building and analyzing recommender systems that deal with explicit rating data. We will be using it to develop and train our recommender models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "36jOEMGgWKfY"
   },
   "source": [
    "### Collaborative Filtering\n",
    "\n",
    "A technique that can filter out items that a user might like on the basis of reactions by similar users.\n",
    "\n",
    "It works by searching for a group of people with similar taste to this specific users using matrices.\n",
    "The idea behind matrix factorization is to represent users and items in a lower dimensional latent space. It is then used as a method to predict a rating for a user item pair based on the history of ratings given by the user and given to the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a content latent matrix from movie metadata:\n",
    "# using tf-idf vectors and truncated SVD :\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(Final['metadata'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=Final.index.tolist())\n",
    "print(tfidf_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the first 200 components explain over 50% of the variance within the data?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compressing with SVD\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=200)\n",
    "latent_matrix = svd.fit_transform(tfidf_df)\n",
    "\n",
    "# Plotting the variance expalined to see what latent dimensions to use:\n",
    "explained = svd.explained_variance_ratio_.cumsum()\n",
    "plt.plot(explained, '.-', ms = 16, color='red')\n",
    "plt.xlabel('Singular value components', fontsize= 12)\n",
    "plt.ylabel('Cumulative percent of variance', fontsize=12)        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping 200 latent dimensions: \n",
    "n = 200 \n",
    "latent_matrix_1_df = pd.DataFrame(latent_matrix[:,0:n], index=Final.title.tolist())\n",
    "\n",
    "# our content latent matrix:\n",
    "latent_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a collaborative latent matrix from user ratings: \n",
    "# We use only a subset of the data to make it possible to pivot the rating dataframe\n",
    "ratings_f = ratings[:3000000]\n",
    "ratings_f1 = pd.merge(movies[['movieId']], ratings_f, on=\"movieId\", how=\"right\")\n",
    "\n",
    "ratings_f2 = ratings_f1.pivot(index = 'movieId', columns ='userId', values = 'rating').fillna(0)\n",
    "ratings_f2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same number of dimensions as before\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=200)\n",
    "latent_matrix_2 = svd.fit_transform(ratings_f2)\n",
    "latent_matrix_2_df = pd.DataFrame(\n",
    "                             latent_matrix_2,\n",
    "                             index=Final.title.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the variance expalined to see what latent dimensions to use\n",
    "explained = svd.explained_variance_ratio_.cumsum()\n",
    "plt.plot(explained, '.-', ms = 16, color='red')\n",
    "plt.xlabel('Singular value components', fontsize= 12)\n",
    "plt.ylabel('Cumulative percent of variance', fontsize=12)        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxE8pByAXxe4"
   },
   "source": [
    "### Content Based Filtering\n",
    "\n",
    "A Content based filter uses attributes to recommend similar content.\n",
    "\n",
    "In a content-based recommender system, keywords are used to describe the items and a user profile is built to indicate the type of item this user likes. In other words, these algorithms try to recommend items that are similar to those that a user liked in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "PKnhXRqzmRJs",
    "outputId": "894dded7-81fc-43d9-8af5-e92bcaf94042"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-5d8874a2-1edc-4d0a-8c73-0bf6ade8b11c\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-5d8874a2-1edc-4d0a-8c73-0bf6ade8b11c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving imdb_data.csv to imdb_data (3).csv\n",
      "Saving movies.csv to movies (2).csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "ZU06HQ2LYiXR",
    "outputId": "c9c9bc88-532f-4abc-c7d9-02ea4f9283cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  ...                                       genres\n",
       "0        1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
       "1        2  ...                   Adventure|Children|Fantasy\n",
       "2        3  ...                               Comedy|Romance\n",
       "3        4  ...                         Comedy|Drama|Romance\n",
       "4        5  ...                                       Comedy\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In order to best recommend a movie, we need to look at the list of movies we have. \n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTcRDthBoZTx"
   },
   "outputs": [],
   "source": [
    "#movies = pd.read_csv('movies.csv')\n",
    "#imdb = pd.read_csv('imdb_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7p_KhNCZX-A"
   },
   "source": [
    "Other features that could help or influence what a user may like include the cast, director or keywords.\n",
    "- This data can all be found in the imdb dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "fH9NFm00Yieb",
    "outputId": "70e6b86c-9477-45b2-bac0-570c506b176e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title_cast</th>\n",
       "      <th>director</th>\n",
       "      <th>runtime</th>\n",
       "      <th>budget</th>\n",
       "      <th>plot_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Tom Hanks|Tim Allen|Don Rickles|Jim Varney|Wal...</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>81.0</td>\n",
       "      <td>$30,000,000</td>\n",
       "      <td>toy|rivalry|cowboy|cgi animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Robin Williams|Jonathan Hyde|Kirsten Dunst|Bra...</td>\n",
       "      <td>Jonathan Hensleigh</td>\n",
       "      <td>104.0</td>\n",
       "      <td>$65,000,000</td>\n",
       "      <td>board game|adventurer|fight|game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Walter Matthau|Jack Lemmon|Sophia Loren|Ann-Ma...</td>\n",
       "      <td>Mark Steven Johnson</td>\n",
       "      <td>101.0</td>\n",
       "      <td>$25,000,000</td>\n",
       "      <td>boat|lake|neighbor|rivalry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Whitney Houston|Angela Bassett|Loretta Devine|...</td>\n",
       "      <td>Terry McMillan</td>\n",
       "      <td>124.0</td>\n",
       "      <td>$16,000,000</td>\n",
       "      <td>black american|husband wife relationship|betra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Steve Martin|Diane Keaton|Martin Short|Kimberl...</td>\n",
       "      <td>Albert Hackett</td>\n",
       "      <td>106.0</td>\n",
       "      <td>$30,000,000</td>\n",
       "      <td>fatherhood|doberman|dog|mansion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  ...                                      plot_keywords\n",
       "0        1  ...                   toy|rivalry|cowboy|cgi animation\n",
       "1        2  ...                   board game|adventurer|fight|game\n",
       "2        3  ...                         boat|lake|neighbor|rivalry\n",
       "3        4  ...  black american|husband wife relationship|betra...\n",
       "4        5  ...                    fatherhood|doberman|dog|mansion\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBl6l8H7aDX_"
   },
   "source": [
    "The Combined relevant datasets\n",
    "\n",
    "The movie database has movie titles and genres and the imdb database has the cast, directors and keywords.\n",
    "We make it easier to view all of this information by combining them into one dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "upMUaDoTYiao",
    "outputId": "28576c5c-1d3c-4408-896b-60541efef0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>title_cast</th>\n",
       "      <th>director</th>\n",
       "      <th>runtime</th>\n",
       "      <th>budget</th>\n",
       "      <th>plot_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>Tom Hanks|Tim Allen|Don Rickles|Jim Varney|Wal...</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>81.0</td>\n",
       "      <td>$30,000,000</td>\n",
       "      <td>toy|rivalry|cowboy|cgi animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>Robin Williams|Jonathan Hyde|Kirsten Dunst|Bra...</td>\n",
       "      <td>Jonathan Hensleigh</td>\n",
       "      <td>104.0</td>\n",
       "      <td>$65,000,000</td>\n",
       "      <td>board game|adventurer|fight|game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>Walter Matthau|Jack Lemmon|Sophia Loren|Ann-Ma...</td>\n",
       "      <td>Mark Steven Johnson</td>\n",
       "      <td>101.0</td>\n",
       "      <td>$25,000,000</td>\n",
       "      <td>boat|lake|neighbor|rivalry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>Whitney Houston|Angela Bassett|Loretta Devine|...</td>\n",
       "      <td>Terry McMillan</td>\n",
       "      <td>124.0</td>\n",
       "      <td>$16,000,000</td>\n",
       "      <td>black american|husband wife relationship|betra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Steve Martin|Diane Keaton|Martin Short|Kimberl...</td>\n",
       "      <td>Albert Hackett</td>\n",
       "      <td>106.0</td>\n",
       "      <td>$30,000,000</td>\n",
       "      <td>fatherhood|doberman|dog|mansion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  ...                                      plot_keywords\n",
       "0        1  ...                   toy|rivalry|cowboy|cgi animation\n",
       "1        2  ...                   board game|adventurer|fight|game\n",
       "2        3  ...                         boat|lake|neighbor|rivalry\n",
       "3        4  ...  black american|husband wife relationship|betra...\n",
       "4        5  ...                    fatherhood|doberman|dog|mansion\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alls = metadata.copy()\n",
    "alls.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "oY3HvyDeYiQd",
    "outputId": "0ebaeb3a-bef7-45e1-8291-d5d81e1cd1d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId              0\n",
       "title                0\n",
       "genres               0\n",
       "title_cast        9665\n",
       "director          9519\n",
       "runtime          11345\n",
       "budget           17583\n",
       "plot_keywords    10482\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "alls.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "0DEArcXqcR8X",
    "outputId": "2efe472d-3773-4455-e08c-700bbe11c9da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId              0\n",
       "title                0\n",
       "genres               0\n",
       "title_cast           0\n",
       "director             0\n",
       "runtime          11345\n",
       "budget           17583\n",
       "plot_keywords        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replac the null values.\n",
    "alls['title_cast'] = alls['title_cast'].fillna('')\n",
    "alls['director'] = alls['director'].fillna('')\n",
    "alls['plot_keywords'] = alls['plot_keywords'].fillna('')\n",
    "alls.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQcOnowBc5rn"
   },
   "source": [
    "We obeserve that both _Runtime_ and _budget_ do not really influence a user's choice in movie preferences so we drop it these columns rather than impute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqh4Av9kcSDx"
   },
   "outputs": [],
   "source": [
    "# Dropping columns that are not useful\n",
    "alls = alls.drop(['runtime', 'budget'], axis = 1)\n",
    "alls = alls.drop('movieId', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "dCLPRycsc4lV",
    "outputId": "b44e8782-dac9-4c48-d607-37e40daf1739"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            0\n",
       "genres           0\n",
       "title_cast       0\n",
       "director         0\n",
       "plot_keywords    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "alls.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44yWT1-te8xs"
   },
   "source": [
    "The dataframe is now cleaned so we move on to convert the data to lowercase and remove any spaces to ensure our system does not confuse names or movies that may start with the same first words.\n",
    "eg 'James Bond' and 'James Carter' may come across as the same character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lsci5dHEeLl1"
   },
   "outputs": [],
   "source": [
    "# Creating a function to clean the metadata\n",
    "def clean(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        \n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-uEe9De-eLpX"
   },
   "outputs": [],
   "source": [
    "# Applying the cleaning function\n",
    "for items in alls:\n",
    "    alls[items] = alls[items].apply(clean)\n",
    "\n",
    "# Looking at the cleaned dataframe\n",
    "alls.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnzUQ1K4gtdc"
   },
   "source": [
    "Now that we have clean the relevant data, we create our metadata soup that will be used in vectorizing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZMxW6WAShC2C"
   },
   "outputs": [],
   "source": [
    "# This function generates normlized text values that will be easy to vectorize\n",
    "def soup(x):\n",
    "    return ' '.join(x['genres']) + ' ' + ' '.join(x['title_cast']) + ' ' + x['director'] + ' ' + ' '.join(x['plot_keywords'])\n",
    "alls['soup'] = alls.apply(soup, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G2LQra7rhC5u"
   },
   "outputs": [],
   "source": [
    "# We then _reset the index_ so as to generate a new dataframe setting the indices in order, \n",
    "# starting from 0, making it easier to work with the dataframe.\n",
    "alls = alls.reset_index()\n",
    "indices = pd.Series(alls.index, index=alls['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Lo2shYjhyDm"
   },
   "source": [
    "CountVectorizer counts the word frequencies, unlike the TFIDFVectorizer we have used before in which the value increases proportionally to count, but is inversely proportional to frequency of the word in the corpus; that is the inverse document frequency (IDF) part.\n",
    "\n",
    "CountVectorizer thus provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words. Also enabling the preprocessing of text data prior to generating the vector representation making it a highly flexible feature representation module for text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oXiQTFZahDAF"
   },
   "outputs": [],
   "source": [
    "# Creating the instance of cv\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(alls['soup'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dIbvEbAzipTe"
   },
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "A metric used to determine how similar the data is. It measures similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. It is different to the latent matrix whereby the user and item vectors are often called latent vectors are low-dimensional embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwP5UxprhC9X"
   },
   "outputs": [],
   "source": [
    "# Creating the instance of csine similarity\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlL-zM4XjLXa"
   },
   "outputs": [],
   "source": [
    "# This function considers all our relevant features along with the cosine similarity \n",
    "# then returns a list of recommended movies. \n",
    "def reco(title, cosine_sim = cosine_sim):\n",
    "    \n",
    "    index = indices[title]\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[index]))\n",
    "    sims = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sims = sims[1:11]\n",
    "\n",
    "    movie_indices = [i[0] for i in sims]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return alls['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5Pom667kgAS"
   },
   "source": [
    "Finally we are now able to suggest a movie and find other similar movies for our user to watch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#) Running a content / collaborative and hybrid cosine Similarity:\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#) We  the latent vectors for a selected movie from both content and collaborative matrixes:\n",
    "a_1 = np.array(latent_matrix_1_df.loc['Toy Story']).reshape(1, -1)\n",
    "a_2 = np.array(latent_matrix_2_df.loc['Toy Story']).reshape(1, -1)\n",
    "\n",
    "#) Then calculate the similartity of this movie with the others in the list:\n",
    "score_1 = cosine_similarity(latent_matrix_1_df, a_1).reshape(-1)\n",
    "score_2 = cosine_similarity(latent_matrix_2_df, a_2).reshape(-1)\n",
    "\n",
    "#) Find an average measure of both content and collaborative: \n",
    "hybrid = ((score_1 + score_2)/2.0)\n",
    "\n",
    "#) Finally formulate a data frame of similar movies:\n",
    "dictDf = {'content': score_1 , 'collaborative': score_2, 'hybrid': hybrid} \n",
    "similar = pd.DataFrame(dictDf, index = latent_matrix_1_df.index )\n",
    "\n",
    "#) Sort the dataframe on the basis of either: content, collaborative or hybrid,  i.e content\n",
    "similar.sort_values('content', ascending=False, inplace=True)\n",
    "\n",
    "similar[1:].head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise\n",
    "cont."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic algorithms used in recommender systems:\n",
    "\n",
    "- NormalPredictor: predicts a random rating based on the distribution of the training set, which is assumed to be normal.\n",
    "- BaselineOnly: predicts the baseline estimate for given user and item.\n",
    "- KNNBasic: a basic collaborative filtering algorithm.\n",
    "- KNNWithMeans: a basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "- KNNBaseline: is a basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "- SVD algorithm is equivalent to Probabilistic Matrix Factorization\n",
    "- SVDpp algorithm is an extension of SVD that takes into account implicit ratings.\n",
    "- NMF is a collaborative filtering algorithm based on Non-negative Matrix Factorization. It is very similar with SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKOcx1FDWeAC"
   },
   "outputs": [],
   "source": [
    "from surprise import SVD, SVDpp, NormalPredictor, KNNBasic, BaselineOnly\n",
    "# Benchmarking algorithms\n",
    "models = ['SVD', 'SVDpp', 'NormalPredictor', 'KNNBasic', 'BaselineOnly']\n",
    "performance = [] # empty list to capture rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data to benchmark on:\n",
    "data = Dataset.load_from_df(train_df, reader=reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "for model in [SVD, SVDpp, NormalPredictor, KNNBasic, BaselineOnly]:\n",
    "    \n",
    "    # Create an instance of the model\n",
    "    algo = model()\n",
    "    # Fit the model to the training data\n",
    "    algo.fit(trainset)\n",
    "    # Generate predictions\n",
    "    predictions = algo.test(testset)\n",
    "    # Compare predictions against actuals\n",
    "    rating_pred = accuracy.rmse(predictions)\n",
    "    # Extract only the name of the model\n",
    "    performance.append(rating_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to store the rmse results of the models\n",
    "results = pd.DataFrame(data=performance, columns=['rmse'], index=models)\n",
    "# Sorting the results from best performance to worst\n",
    "results.sort_values('rmse', inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VyuYO6D9WhqM"
   },
   "source": [
    "SVD\n",
    "\n",
    "The Singular Value Decomposition (SVD), is a matrix factorisation technique, which reduces the number of features of a dataset by reducing the space dimension from N-dimension to K-dimension (where K < N), it is of no suprise that it and the SVDpp performed best out of the other models. Since SVD and SVDpp had the least RMSE value, we will tune the hyper-parameters of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning algorithm parameters with GridSearchCV to find the best parameters for the algorithm.\n",
    "# Using a subset of the data so that it runs quicker:\n",
    "ratings = ratings[:50000]\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(ratings[['userId' ,'movieId', 'rating']], reader)\n",
    "\n",
    "from surprise.model_selection.search import GridSearchCV\n",
    "param_grid = {'n_factors': [25, 30, 35, 40, 100], 'n_epochs': [15, 20, 25], 'lr_all': [0.001, 0.003, 0.005, 0.008],               'reg_all': [0.08, 0.1, 0.15, 0.02]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "algo = gs.best_estimator['rmse']\n",
    "print(gs.best_score['rmse']) \n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "# Assigning the values\n",
    "best = gs.best_params \n",
    "factors = best['rmse']['n_factors']\n",
    "epochs = best['rmse']['n_epochs'] \n",
    "lr_value = best['rmse']['lr_all']\n",
    "reg_value = best['rmse']['reg_all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R2PfH1i3W7vC"
   },
   "source": [
    "Now we train our dataset and arrive at a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ft8PtGf8WeDT"
   },
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "train = Dataset.load_from_df(train[['userId', 'movieId', 'rating']], reader)\n",
    "svd = SVD(factors, epochs, lr_value, reg_value)\n",
    "data_train = train.build_full_trainset()\n",
    "svd.fit(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNlFoU73XGYH"
   },
   "source": [
    "Breakdown of what is put into the model:\n",
    "\n",
    "\n",
    "* a = userId\n",
    "* b = movieId\n",
    "* c = rating\n",
    "* d = expected rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GcyyFT94WeIj"
   },
   "outputs": [],
   "source": [
    "a = \n",
    "b =\n",
    "c ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cU-RCt_WeGc"
   },
   "outputs": [],
   "source": [
    "d = svd.predict(a, b, c)\n",
    "print (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cqTYdSCyXV9_"
   },
   "source": [
    "For our prediction, we give the model a different users info (userId, movieId and their rating). It will then predict an estimate of what our user may rate this movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LMdofqynGa1"
   },
   "source": [
    "## 7. Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtkahZdfnJbn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MxZE3w3JnRAY"
   },
   "source": [
    "## 8. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQ9B_LqpnVPY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hfDs7QiAIvAL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tg212rryIvAO"
   },
   "source": [
    "## 9. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ozHsutcsk7Nf"
   },
   "source": [
    "1. Beginner Tutorial: Recommender Systems in Python\n",
    "https://www.datacamp.com/community/tutorials/recommender-systems-python\n",
    "\n",
    "2. Building Recommender Systems with Machine Learning and AI\n",
    "https://explore.udemy.com/course/building-recommender-systems-with-machine-learning-and-ai/learn/lecture/18187952#overview\n",
    "\n",
    "3. Build a Recommendation Engine With Collaborative Filtering\n",
    "https://realpython.com/build-recommendation-engine-collaborative-filtering/\n",
    "\n",
    "4. How to Build Simple Recommender Systems in Python\n",
    "https://medium.com/swlh/how-to-build-simple-recommender-systems-in-python-647e5bcd78bd\n",
    "\n",
    "5. Introduction to Recommendation System. Part 1\n",
    "https://hackernoon.com/introduction-to-recommender-system-part-1-collaborative-filtering-singular-value-decomposition-44c9659c5e75\n",
    "\n",
    "6. Building a Recommender System With Pandas\n",
    "https://medium.com/towards-artificial-intelligence/building-a-recommender-system-with-pandas-1ca0bb03fdce\n",
    "\n",
    "7. Building and Testing Recommender Systems With Surprise, Step-By-Step\n",
    "https://towardsdatascience.com/building-and-testing-recommender-systems-with-surprise-step-by-step-d4ba702ef80b\n",
    "\n",
    "8. Prototyping a Recommender System Step by Step Part 1: KNN Item-Based Collaborative Filtering\n",
    "https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-1-knn-item-based-collaborative-filtering-637969614ea\n",
    "\n",
    "9. Suprise\n",
    "http://surpriselib.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Team_EN3_JHB_Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
